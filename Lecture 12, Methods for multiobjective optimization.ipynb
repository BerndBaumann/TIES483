{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 12, Methods for multiobjective optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about the topic of this lecture, I urge you to read Professor Miettinen's book Nonlinear Multiobjective Optimization\n",
    "\n",
    "![Nonlinear Multiobjective Optimization](images/Miettinen2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for multiobjective optimization are often charactermized by the involvement of the decision maker in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of methods are\n",
    "* **no preference methods**, where the decision maker does not play a role,\n",
    "* **a priori methods**, where the decision maker gives his/her preference information at first and then the optimization method find the best match to that preference information,\n",
    "* **a posteriori methods**, where the optimization methods try to characterize all/find a good represenatation of the Pareto optimal solutions and the decision maker chooses the most preferred one of those,\n",
    "* **interactive methods**, where the optimization method and the decision maker alternate in iteratively search for the most preferred solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Our example problem for this lecture\n",
    "\n",
    "We study a hypothetical decision problem of buying a car, when you can choose to have a car with power between (denoted by $p$) 50 and 200 kW and average consumption (denoted by $c$) per 100 km between 3 and 10 l. However, in addition to the average consumption and power, you need to decide the volume of the cylinders (v), which may be between 1000 $cm^3$ and $4000cm^3$. Finally, the price of the car follows now a function \n",
    "$$\n",
    "\\left(\\sqrt{\\frac{p-50}{50}}\\\\\n",
    "+\\left(\\frac{p-50}{50}\\right)^2+0.3(10-c)\\\\ +10^{-5}\\left(v-\\left(1000+3000\\frac{p-50}{150}\\right)\\right)^2\\right)10000\\\\+5000\n",
    "$$\n",
    "in euros. This problem can be formulated as a multiobjective optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\quad & \\{c,-p,P\\},\\\\\n",
    "\\text{s.t. }\\quad\n",
    "&50\\leq p\\leq 200\\\\\n",
    "&3\\leq c\\leq 10\\\\\n",
    "&1000\\leq v\\leq 4000,\\\\\n",
    "\\text{where }\\quad&P = \\left(\\sqrt{\\frac{p-50}{50}}+\\frac{p-50}{50}^2+\\frac{10-c}{10} +\\right.\\\\\n",
    "&\\left.\\frac{p-50}{50}\\frac{10-c}{10}\\right)10000+5000\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Let us define a Python function which returns the value of this\n",
    "import math\n",
    "def car_problem(c,p,v):\n",
    "#    import pdb; pdb.set_trace()\n",
    "    return [#Objective function values\n",
    "        c,-p,\n",
    "        (math.sqrt((p-40.)/50.)+((p-50.)/50.)**2+\n",
    "        0.3*(10.-c)+0.00001*(v-(1000.+3000.*(p-50.)/150.))**2)*10000.\n",
    "        +5000.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car with 3 l/100km consumption, 50kW and 1000$cm^3$ engine would cost 30472.135955€\n",
      "Car with 3 l/100km consumption, 100kW and 2000$cm^3$ engine would cost 46954.4511501€\n",
      "Car with 3 l/100km consumption, 100kW and 1000$cm^3$ engine would cost 146954.45115€\n"
     ]
    }
   ],
   "source": [
    "print(\"Car with 3 l/100km consumption, 50kW and 1000$cm^3$ engine would cost \"\n",
    "      +str(car_problem(3,50,1000)[2])+\"€\")\n",
    "print(\"Car with 3 l/100km consumption, 100kW and 2000$cm^3$ engine would cost \"\n",
    "      +str(car_problem(3,100,2000)[2])+\"€\")\n",
    "print(\"Car with 3 l/100km consumption, 100kW and 1000$cm^3$ engine would cost \"\n",
    "      +str(car_problem(3,100,1000)[2])+\"€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization of the objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In many of the methods, the normalization of the objectives is necessary. **\n",
    "\n",
    "We can normalize the objectives using the nadir and ideal and setting the normalized objective as\n",
    "$$ \\tilde f_i = \\frac{f_i-z_i^{ideal}}{z_i^{nadir}-z_i^{ideal}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating the ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the ideal for problems is usually easy, if you can optimize the objective functions separately.**\n",
    "\n",
    "For the car problem, ideal can be computed easily using the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating the ideal\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "def calc_ideal(f):\n",
    "    ideal = [0]*3 #Because three objectives\n",
    "    solutions = [] #list for storing the actual solutions, which give the ideal\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    for i in range(3):\n",
    "        res=minimize(\n",
    "            #Minimize each objective at the time\n",
    "            lambda x: f(x[0],x[1],x[2])[i], [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(lambda x: f(x[0],x[1],x[2])[i])[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,\n",
    "            options = {'disp':True})\n",
    "        solutions.append(f(res.x[0],res.x[1],res.x[2]))\n",
    "        ideal[i]=res.fun\n",
    "    return ideal,solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 3.0\n",
      "            Iterations: 1\n",
      "            Function evaluations: 1\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -200.0\n",
      "            Iterations: 5\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 9371.55596176\n",
      "            Iterations: 10\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "ideal is [3.0, -200.0, 9371.5559617552626]\n"
     ]
    }
   ],
   "source": [
    "ideal, solutions= calc_ideal(car_problem)\n",
    "print (\"ideal is \"+str(ideal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pay-off table method\n",
    "\n",
    "**Finding the nadir value is however, usually much harder.**\n",
    "\n",
    "Usually, the nadir value is estimated using the so-called pay-off table method.\n",
    "\n",
    "The pay-off table method does not guarantee to find the nadir for problems with more than two objectives. (One of your exercises this week will be to show this.) \n",
    "\n",
    "The method is, however, a generally accepted way of approximating the nadir vector.\n",
    "\n",
    "In the pay-off table method:\n",
    "1. the objective values for attaining the individual minima are added in table\n",
    "2. the nadir is estimated by each objectives maxima in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nadir for the car selection problem\n",
    "The table now becomes by using the *solutions* that we returned while calculating the ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, -50.0, 30472.13595499958]\n",
      "[3.0, -200.0, 1033888.5438199985]\n",
      "[10.033526664414772, -50.0, 9371.5559617552626]\n"
     ]
    }
   ],
   "source": [
    "for solution in solutions:\n",
    "    print solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Thus, the esimation of the nadir vector is \n",
    "$$(10,-50,1033888.543820).$$\n",
    "\n",
    "This is actually the real Nadir vector for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalized car problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Let us define a Python function which returns the value of this\n",
    "import math\n",
    "def car_problem_normalized(c,p,v):\n",
    "    z_ideal = [3.0, -200.0, 9472.1359549995796]\n",
    "    z_nadir = [10,-50,1033888.543820]\n",
    "#    import pdb; pdb.set_trace()\n",
    "    z = car_problem(c,p,v) \n",
    "    return [(zi-zideali)/(znadiri-zideali) for \n",
    "            (zi,zideali,znadiri) in zip(z,z_ideal,z_nadir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized value of the car problem at (3,50,1000) is [0.0, 1.0, 0.020499476422645723]\n",
      "Normalized value of the car problem at (3,125,2500) is [0.0, 0.5, 0.05082529765792966]\n",
      "Normalized value of the car problem at (10,100,1000) is [1.0, 0.6666666666666666, 0.11370602257129601]\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized value of the car problem at (3,50,1000) is \"\n",
    "      +str(car_problem_normalized(3,50,1000)))\n",
    "print(\"Normalized value of the car problem at (3,125,2500) is \"\n",
    "      +str(car_problem_normalized(3,125,2500)))\n",
    "print(\"Normalized value of the car problem at (10,100,1000) is \"\n",
    "      +str(car_problem_normalized(10,100,1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** So, value 1 now indicates the worst value on the Pareto frontier and value 0 indicates the best values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the ideal and nadir for later reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_ideal = [3.0, -200.0, 9472.1359549995796]\n",
    "z_nadir = [10.,-50,1033888.543820]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From now on, we will deal with the normalized problem, although, we write just $f$.** The aim of this is to simplify presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## No preference methods\n",
    "\n",
    "* Usually only for situations, where the decision maker is not available or does not want to get involved\n",
    "* These just compute a single Pareto optimal solution, which is in somehow mathematically thought as the best compromise\n",
    "\n",
    "## Notation\n",
    "\n",
    "For short, let us denote the feasible set $\\{x\\in\\mathbb R^n: g_j(x) \\geq 0 \\text{ for all }j=1,\\ldots,J \\text{ and } h_k(x) = 0\\text{ for all }k=1,\\ldots,K\\}$ by $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Method of Global criterion\n",
    "\n",
    "Involved minimization of the p-norm of $f(x)-z^{ideal}$, that is we solve the problem\n",
    "$$\n",
    "\\min_{x\\in S} \\|f(x) - z^{ideal}\\|_p.\n",
    "$$\n",
    "\n",
    "![alt text](images/mgc.svg \"Method of global criterion\")\n",
    "\n",
    "**An optimal solution to this problem is Pareto optimal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying to our problem studied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def global_criterion_method(f,p):\n",
    "    #Ideal for any normalized problem is (0,0,0)\n",
    "    ideal = [0,0,0]\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    #Objective is the norm of objective function values minus\n",
    "    #the ideal\n",
    "    obj = lambda x: np.linalg.norm(np.array(f(x[0],x[1],x[2]))\n",
    "                                   -np.array(ideal),ord=p)\n",
    "    res=minimize(\n",
    "            #Minimize p distance from the ideal\n",
    "            obj, [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(obj)[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,options = {'disp':True})\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.549669334387\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      " variable values are  [    3.05211179   138.12821175  1000.00729216]\n",
      "objective values are  [3.0521117947829333, -138.12821174914697, 381579.84409750014]\n"
     ]
    }
   ],
   "source": [
    "solution = global_criterion_method(car_problem_normalized,\n",
    "                                           2)\n",
    "print \"variable values are \",solution\n",
    "f_global_criterion = car_problem(solution[0],solution[1],solution[2])\n",
    "print \"objective values are \",f_global_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A posteriori methods\n",
    "\n",
    "* A posteriori methods generate a representation of the Pareto optimal solutions, or the complete set of Pareto optimal solutions\n",
    "* Benefits\n",
    "  * The solutions can be visualized for problems with 2 or 3 objectives so the decision making is possible\n",
    "  * When succesful, they give an understanding of the Pareto front\n",
    "* Drawbacks\n",
    "  * Approximating the Pareto optimal set often time-consuming\n",
    "  * Decision making from a large representation may be very difficut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### The weighting method\n",
    "\n",
    "Based on solving optimization problem\n",
    "$$\n",
    "\\min_{x\\in S} \\sum_{i=1}^kw_if_i(x)\n",
    "$$\n",
    "for different weights $w_i\\geq0$, $i=1,\\ldots,k$. \n",
    "\n",
    "**The idea is to generate weights evenly and then have evenly spread solutions.**\n",
    "\n",
    "**An optimal solution the weighted problem is Pareto optimal, if all the weights $w_i$ are $>0$.**\n",
    "\n",
    "![alt text](images/ws.svg \"Weighting method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Application to our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def weighting_method(f,w):\n",
    "    points = []\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    for wi in w:\n",
    "        res=minimize(\n",
    "            #weighted sum\n",
    "            lambda x: sum(np.array(wi)*np.array(f(x[0],x[1],x[2]))), \n",
    "            [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(lambda x: sum(np.array(wi)*np.array(f(x[0],x[1],x[2]))))[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,options = {'disp':False})\n",
    "        points.append(res.x)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.random.random((500,3)) #500 random weights\n",
    "repr = weighting_method(car_problem_normalized,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "f_repr_ws = [car_problem(repri[0],repri[1],repri[2]) for repri in repr]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter([f[0] for f in f_repr_ws],[f[1] for f in f_repr_ws],[f[2] for f in f_repr_ws])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epsilon-constraint method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on solving optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\quad &f_j(x)\\\\\n",
    "\\text{s.t. }\\quad &x\\in S\\\\\n",
    "&f_i(x)\\leq \\epsilon_i \\text{ for all }i\\neq j\n",
    "\\end{align}\n",
    "$$\n",
    "for different bounds $\\epsilon_i, $i\\neq j$. \n",
    "\n",
    "**The idea is to generate $\\epsilon$ evenly within the bounds of the ideal and nadir vectors and then have evenly spread solutions.**\n",
    "\n",
    "**A solution is Pareto optimal $x^*$, if it is the solution to the epsilon constraint problem for all $j=1,\\ldots,k$ and $\\epsilon = f(x^*)$.**\n",
    "\n",
    "![alt text](images/eps.svg \"Epsilon constraint method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Application to our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "def e_constraint_method(f,eps,z_ideal,z_nadir):\n",
    "    points = []\n",
    "    for epsi in eps:\n",
    "        bounds = ((3,epsi[0]*(z_nadir[0]-z_ideal[0])+z_ideal[0]),\n",
    "                  (-1.*(epsi[1]*(z_nadir[1]-z_ideal[1])+z_ideal[1]),\n",
    "                   200),(1000,4000)) #Added bounds for two first objectives\n",
    "        res=minimize(\n",
    "            #Third objective\n",
    "            lambda x: f(x[0],x[1],x[2])[2], \n",
    "            [3,200,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(lambda x: f(x[0],x[1],x[2])[2])[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,options = {'disp':False})\n",
    "        if res.success:\n",
    "            points.append(res.x)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = np.random.random((100,2))\n",
    "repr = e_constraint_method(car_problem_normalized,eps,z_ideal,z_nadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "f_repr_eps = [car_problem(repri[0],repri[1],repri[2]) for repri in repr]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter([f[0] for f in f_repr_eps],[f[1] for f in f_repr_eps],[f[2] for f in f_repr_eps])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison of the weighted sum method and the epsilon constraint method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "f_repr_eps = [car_problem(repri[0],repri[1],repri[2]) for repri in repr]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#Mark solutions to epsilon constsraint problem using crosses\n",
    "ax.scatter([f[0] for f in f_repr_eps],[f[1] for f in f_repr_eps],\n",
    "           [f[2] for f in f_repr_eps],marker='x')\n",
    "#Mark solutions to weighted sum problem using dots\n",
    "ax.scatter([f[0] for f in f_repr_ws],[f[1] for f in f_repr_ws],\n",
    "           [f[2] for f in f_repr_ws],marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The weighting method can find all the Pareto optimal solutions only, when the objective functions are convex and the feasible set $S$ is convex.** \n",
    "\n",
    "**The weighting method produces very unevenly spread Pareto optimal solutions, even when the problem is convex. ** \n",
    "\n",
    "**The epsilon constraint method, however, adds constraints to the problem, which may make it much harder to solve**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A priori methods\n",
    "\n",
    "* A priori methods ask for preferences from the decision maker, and then find the Pareto optimal solution that best matches these preferences\n",
    "* Benefits\n",
    "  * If the decision maker knows what he/she wants and understands the preference information asked for, then application is fast\n",
    "* Drawbacks\n",
    "  * The decision maker may not know what he/she wants, because he does not know the Pareto optimal solutions\n",
    "  * The decision maker may not understand how the preferences he/she gives affect the solutions found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Achievement scalarizing problem\n",
    "\n",
    "There are multiple versions of the achievement scalarizing problem, but all of them are based on a refence point.\n",
    "\n",
    "A reference point\n",
    "$$z^{ref} = (z^{red}_1,\\ldots,z^{ref}_i)$$\n",
    "contains preferable values (so-called aspiration levels) for the objectives.\n",
    "\n",
    "Then the achievement scalarizing problem maps this point and a feasible solution to the multiobjective problem to a scalar (i.e., scalarizes it). One of the most commonly used is\n",
    "$$\n",
    "\\min_{x\\in S}\\left( \\max_{i=1}^k(f_i(x)-z_i) +\\rho\\sum_{i=1}^nf_i(x)\\right)\n",
    "$$\n",
    "where $\\rho>0$ is a small value. The second part is called an augmentation term.\n",
    "\n",
    "** The solution to the problem is guaranteed to be Pareto optimal **\n",
    "\n",
    "** Any (properly) Pareto optimal solution can be found with some reference point**\n",
    "\n",
    "![alt text](images/ach.svg \"Achievement scalarizing method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Application to our car problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "def asf(f,ref,z_ideal,z_nadir,rho):\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    #Normalizing the reference point\n",
    "    ref_norm = [(refi-z_ideali)/(z_nadiri-z_ideali) \n",
    "                for (refi,z_ideali,z_nadiri) in zip(ref,z_ideal,z_nadir)]\n",
    "    obj = lambda x: (np.max(np.array(f(x[0],x[1],x[2]))-ref_norm)\n",
    "           +rho*np.sum(f(x[0],x[1],x[2])))\n",
    "    res=minimize(\n",
    "        #Objective function defined above\n",
    "        obj, \n",
    "        [3,200,1000], method='SLSQP'\n",
    "        #Jacobian using automatic differentiation\n",
    "        ,jac=ad.gh(obj)[0]\n",
    "        #bounds given above\n",
    "        ,bounds = bounds,options = {'disp':True})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rho = 0.000001\n",
    "#The reference point for the problem\n",
    "ref =  [] #To be added at the class\n",
    "res = asf(car_problem_normalized,ref,z_ideal,z_nadir,rho)\n",
    "print res.x\n",
    "print \"Price is \",car_problem(res.x[0],res.x[1],res.x[2])[2],\"€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_problem(10,149.70923875,3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive methods\n",
    "\n",
    "* Interactive methods iteratively search for the preferred solution with decision maker and optimization alternating\n",
    "* Benefits\n",
    "  * Decision maker gets to learn about\n",
    "    * the available solutions, and\n",
    "    * how preferences affect the solutions found\n",
    "  * Computation is less intensive, because no need to generate a large representation of Pareto optimal solutions\n",
    "* Drawbacks\n",
    "  * Needs active involvement from the decision maker\n",
    "  * If the proble is computationally expensive, then the decision maker may need to wait a long time between solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interactive methods (cont)\n",
    "\n",
    "**Interactive methods are one of the main research areas here at the Industrial optimization research group**\n",
    "\n",
    "We will study interactive methods using the IND-NIMBUS software developed at the research group.\n",
    "\n",
    "The IND-NIMBUS software contains many different interactive methods.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
